{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2841c3b4-e594-46f5-8160-72c738dcd168",
   "metadata": {},
   "source": [
    "# Impl√©mentation UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2482a7c0-fff1-422f-a2f3-163289603b22",
   "metadata": {},
   "source": [
    "## Importation des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc6a5f4-8e67-4197-9a26-d6250319ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Base Python ===\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# === Typage ===\n",
    "from typing import Optional, Union, Tuple\n",
    "\n",
    "# === NumPy / Math / Visualisation ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "# === PIL (images) ===\n",
    "from PIL import Image\n",
    "\n",
    "# === PyTorch / Torchvision ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# === Monai (medical imaging) ===\n",
    "import monai\n",
    "from monai.transforms import LoadImage\n",
    "\n",
    "# === SimpleITK ===\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# === Affichage mod√®le ===\n",
    "from torchinfo import summary\n",
    "\n",
    "# === Barre de progression ===\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843a020-e82a-475a-8215-5cf0b7f42dac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb9f75-447b-46b9-9358-a4b904e5b342",
   "metadata": {},
   "source": [
    "## Pr√©traitement NII file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14baacb-9df2-4604-83a5-e8087bea3340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ants\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def n4_bias_correct(path_in):\n",
    "    img = sitk.ReadImage(path_in, sitk.sitkFloat32)\n",
    "    mask = sitk.OtsuThreshold(img, 0, 1)\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    corrected = corrector.Execute(img, mask)\n",
    "    return corrected\n",
    "\n",
    "def skull_strip_from_T1(t1_sitk):\n",
    "    arr = sitk.GetArrayFromImage(t1_sitk)\n",
    "    mask = (arr > arr.mean()).astype(\"uint8\")\n",
    "    mask_img = sitk.GetImageFromArray(mask)\n",
    "    mask_img.CopyInformation(t1_sitk)\n",
    "    return mask_img\n",
    "\n",
    "def preprocess_patient(patient_id, input_root=\"./data\", output_root=\"./data_traite\"):\n",
    "    print(f\"\\nüß† Traitement patient : {patient_id}\")\n",
    "    input_dir = os.path.join(input_root, patient_id)\n",
    "    output_dir = os.path.join(output_root, patient_id)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    flair_path = os.path.join(input_dir, \"3DFLAIR.nii\")\n",
    "    t1_path = os.path.join(input_dir, \"3DT1.nii\")\n",
    "    consensus_path = os.path.join(input_dir, \"Consensus.nii\")\n",
    "\n",
    "    if not (os.path.exists(flair_path) and os.path.exists(t1_path) and os.path.exists(consensus_path)):\n",
    "        print(\"‚ùå Fichiers requis manquants\")\n",
    "        return\n",
    "\n",
    "    # N4 + Masque cerveau\n",
    "    t1_corrected = n4_bias_correct(t1_path)\n",
    "    brain_mask = skull_strip_from_T1(t1_corrected)\n",
    "\n",
    "    # ANTsPy : T1 ‚Üí FLAIR\n",
    "    t1_ants = ants.from_numpy(sitk.GetArrayFromImage(t1_corrected))\n",
    "    t1_ants.set_spacing(t1_corrected.GetSpacing())\n",
    "    flair_ants = ants.image_read(flair_path)\n",
    "\n",
    "    reg = ants.registration(fixed=flair_ants, moving=t1_ants, type_of_transform=\"Affine\")\n",
    "\n",
    "    # Warp du masque cerveau\n",
    "    mask_ants = ants.from_numpy(sitk.GetArrayFromImage(brain_mask))\n",
    "    mask_ants.set_spacing(t1_corrected.GetSpacing())\n",
    "    warped_mask = ants.apply_transforms(\n",
    "        fixed=flair_ants,\n",
    "        moving=mask_ants,\n",
    "        transformlist=reg['fwdtransforms'],\n",
    "        interpolator='nearestNeighbor'\n",
    "    )\n",
    "\n",
    "    warped_mask = warped_mask.threshold_image(0.5, 1.1, 1, 0)\n",
    "    flair_stripped = flair_ants * warped_mask\n",
    "\n",
    "    # Sauvegardes\n",
    "    ants.image_write(flair_stripped, os.path.join(output_dir, \"3DFLAIR_traite.nii\"))\n",
    "    os.system(f'cp \"{consensus_path}\" \"{os.path.join(output_dir, \"Consensus_traite.nii\")}\"')\n",
    "    print(\"‚úÖ Sauvegarde OK\")\n",
    "\n",
    "def preprocess_all_patients(input_root=\"./data\", output_root=\"./data_traite\"):\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "    patients = [p for p in os.listdir(input_root) if os.path.isdir(os.path.join(input_root, p))]\n",
    "\n",
    "    for patient_id in patients:\n",
    "        preprocess_patient(patient_id, input_root, output_root)\n",
    "\n",
    "    print(\"\\nüéâ Tous les patients ont √©t√© trait√©s.\")\n",
    "\n",
    "# ‚ñ∂Ô∏è Lancer le traitement global\n",
    "preprocess_all_patients(input_root=\"./data\", output_root=\"./data_traite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e0c2c-0a43-43d3-8636-352113c8e220",
   "metadata": {},
   "source": [
    "## Slicing Data into PNG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e766d4-2244-491c-9b61-449170db5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import SimpleITK as sitk\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "\n",
    "# def preprocess_and_save_slices(input_root, output_root, resized_size=(256, 256)):\n",
    "#     \"\"\"\n",
    "#     Coupe tous les fichiers .nii en slices .png et sauvegarde sur disque.\n",
    "    \n",
    "#     input_root: dossier contenant les sous-dossiers patients avec .nii\n",
    "#     output_root: dossier o√π sauver les slices png\n",
    "#     resized_size: taille des images sauvegard√©es\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "#     for subfolder in os.listdir(input_root):\n",
    "#         folder_path = os.path.join(input_root, subfolder)\n",
    "#         if not os.path.isdir(folder_path):\n",
    "#             continue\n",
    "\n",
    "#         flair_path = os.path.join(folder_path, \"3DFLAIR.nii\")\n",
    "#         mask_path = os.path.join(folder_path, \"Consensus.nii\")\n",
    "\n",
    "#         if not (os.path.exists(flair_path) and os.path.exists(mask_path)):\n",
    "#             continue\n",
    "\n",
    "#         flair_img = sitk.ReadImage(flair_path)\n",
    "#         mask_img = sitk.ReadImage(mask_path)\n",
    "\n",
    "#         flair_array = sitk.GetArrayFromImage(flair_img)  # [D, H, W]\n",
    "#         mask_array = sitk.GetArrayFromImage(mask_img)    # [D, H, W]\n",
    "\n",
    "#         patient_out_folder = os.path.join(output_root, subfolder)\n",
    "#         images_folder = os.path.join(patient_out_folder, \"images\")\n",
    "#         masks_folder = os.path.join(patient_out_folder, \"masks\")\n",
    "\n",
    "#         os.makedirs(images_folder, exist_ok=True)\n",
    "#         os.makedirs(masks_folder, exist_ok=True)\n",
    "\n",
    "#         for idx in range(flair_array.shape[0]):\n",
    "#             img_slice = flair_array[idx]\n",
    "#             mask_slice = mask_array[idx]\n",
    "\n",
    "#             img_slice = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-8)\n",
    "\n",
    "#             img_pil = Image.fromarray((img_slice * 255).astype(np.uint8)).resize(resized_size)\n",
    "#             mask_pil = Image.fromarray((mask_slice > 0).astype(np.uint8) * 255).resize(resized_size)\n",
    "\n",
    "#             img_pil.save(os.path.join(images_folder, f\"slice_{idx:04d}.png\"))\n",
    "#             mask_pil.save(os.path.join(masks_folder, f\"slice_{idx:04d}.png\"))\n",
    "\n",
    "#     print(f\"‚úÖ Slicing termin√© et sauvegard√© sous {output_root}\")\n",
    "\n",
    "# # üî• Comment l'utiliser :\n",
    "# input_root = \"./data\"  # Ton dossier de base contenant les IRMs\n",
    "# output_root = \"./pngData\"  # Dossier o√π sauver les PNG\n",
    "\n",
    "# preprocess_and_save_slices(input_root, output_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf6eaf-464d-40d6-998a-0216e283736f",
   "metadata": {},
   "source": [
    "## Load PNG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27b98c-9ec1-4dbc-80c8-7dcc6b2a6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "\n",
    "class PngSlicesDataset(Dataset):\n",
    "    def __init__(self, root_dir, resized_width=256, resized_height=256, slice_range=None, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "        self.resized_width = resized_width\n",
    "        self.resized_height = resized_height\n",
    "        self.slice_range = slice_range\n",
    "        self.transform = transform if transform is not None else transforms.ToTensor()\n",
    "\n",
    "        patients = os.listdir(root_dir)\n",
    "        for patient in patients:\n",
    "            images_folder = os.path.join(root_dir, patient, \"images\")\n",
    "            masks_folder = os.path.join(root_dir, patient, \"masks\")\n",
    "\n",
    "            if not os.path.isdir(images_folder) or not os.path.isdir(masks_folder):\n",
    "                continue\n",
    "\n",
    "            image_files = sorted(os.listdir(images_folder))\n",
    "\n",
    "            for img_file in image_files:\n",
    "                # Utiliser une expression r√©guli√®re pour d√©tecter slice_XXXX.png\n",
    "                match = re.match(r\"slice_(\\d+)\\.png\", img_file)\n",
    "                if not match:\n",
    "                    continue  # Si ce n'est pas un slice_XXXX.png, on ignore\n",
    "\n",
    "                slice_num = int(match.group(1))\n",
    "\n",
    "                if self.slice_range:\n",
    "                    if not (self.slice_range[0] <= slice_num <= self.slice_range[1]):\n",
    "                        continue\n",
    "\n",
    "                img_path = os.path.join(images_folder, img_file)\n",
    "                mask_path = os.path.join(masks_folder, img_file)\n",
    "\n",
    "                if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_paths.append(mask_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert('L')\n",
    "        mask = Image.open(self.mask_paths[idx]).convert('L')\n",
    "\n",
    "        resize_transform = transforms.Resize((self.resized_height, self.resized_width))\n",
    "\n",
    "        img = resize_transform(img)\n",
    "        mask = resize_transform(mask)\n",
    "\n",
    "        img = self.transform(img)\n",
    "        mask = self.transform(mask)\n",
    "\n",
    "        img = (img - 0.5) / 0.5  # Normaliser [-1,1]\n",
    "        mask = (mask > 0.5).float()  # Binariser\n",
    "\n",
    "        return img, mask, os.path.basename(self.image_paths[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8626d1f5-bfaf-4cc0-b81e-55b54426c6b1",
   "metadata": {},
   "source": [
    "## Define train, test, validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce469e6-0da2-4833-8d25-7894987c48cf",
   "metadata": {},
   "source": [
    "### Here we get the initial image shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f17e3-3d8d-4e48-8fc6-0a55f7f8c428",
   "metadata": {},
   "source": [
    "This value is important, as it will allow us to resize our entire dataset. We must also bear in mind that the size **must be a multiple of two**. This is because, through downsampling (by a factor of two), **we want natural numbers**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1d3dc-0460-4386-9ebd-ff3f56b01caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Dossier d'un patient\n",
    "patient_folder = \"./pngData/01016SACH\"\n",
    "images_folder = os.path.join(patient_folder, \"images\")\n",
    "masks_folder = os.path.join(patient_folder, \"masks\")\n",
    "\n",
    "# Liste des fichiers slices\n",
    "image_files = sorted([f for f in os.listdir(images_folder) if f.endswith('.png')])\n",
    "mask_files = sorted([f for f in os.listdir(masks_folder) if f.endswith('.png')])\n",
    "\n",
    "# Charger un exemple pour conna√Ætre la taille\n",
    "img = Image.open(os.path.join(images_folder, image_files[0]))\n",
    "mask = Image.open(os.path.join(masks_folder, mask_files[0]))\n",
    "\n",
    "# Obtenir largeur et hauteur\n",
    "w, h = img.size\n",
    "print((w, h, len(image_files)), \"W, H, num_slices (√† partir des PNG)\")\n",
    "print((w, h, len(mask_files)), \"W, H, num_slices (masks PNG)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0062876-15b5-46fd-99d9-4f394ffe418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearestMultipleOfTwo(x):\n",
    "    multipleOfTwo = [2**i for i in range(10)]  # [1, 2, 4, ..., 512]\n",
    "    mini = float('inf')\n",
    "    nearest_value = None\n",
    "    \n",
    "    for elem in multipleOfTwo:\n",
    "        difference = abs(elem - x)\n",
    "        if difference < mini:\n",
    "            mini = difference\n",
    "            nearest_value = elem\n",
    "    \n",
    "    return nearest_value\n",
    "\n",
    "#print(getNearestMultipleOfTwo(70)) # -> 64\n",
    "#print(getNearestMultipleOfTwo(150)) # -> 128\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dddbdd5-4df8-4dd7-99fa-0e19fa672c6d",
   "metadata": {},
   "source": [
    "Here we define `width` and `height` of our __dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ab98b-0b93-4b95-8ffa-330a89b40eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = getNearestMultipleOfTwo(w)\n",
    "height = getNearestMultipleOfTwo(h)\n",
    "slice_range = [145, 291]\n",
    "\n",
    "ROOT_DIR = './pngData'\n",
    "\n",
    "train_dataset = PngSlicesDataset(\n",
    "    root_dir=ROOT_DIR,\n",
    "    resized_width=width,\n",
    "    resized_height=height,\n",
    "    slice_range=slice_range\n",
    ")\n",
    "\n",
    "generator = torch.Generator().manual_seed(25)\n",
    "train_dataset, test_dataset = random_split(train_dataset, [0.8, 0.2], generator=generator)\n",
    "print(\"Size dataset :\", len(train_dataset) + len(test_dataset))\n",
    "print(\"Size train_dataset :\", len(train_dataset))\n",
    "print(\"Size test_dataset :\", len(test_dataset))\n",
    "\n",
    "test_dataset, val_dataset = random_split(test_dataset, [0.5, 0.5], generator=generator)\n",
    "print(\"Size train_dataset :\", len(train_dataset))\n",
    "print(\"Size test_dataset :\", len(test_dataset))\n",
    "print(\"Size val_dataset :\", len(val_dataset))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_workers = torch.cuda.device_count() * 4 - 1 if device == \"cuda\" else 1\n",
    "\n",
    "print(\"device:\", device)\n",
    "print(\"num_workers:\", num_workers)\n",
    "\n",
    "LEARNING_RATE = 3e-4\n",
    "BATCH_SIZE = 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8c52e-d875-4f9d-8b2e-3c147f765a49",
   "metadata": {},
   "source": [
    "### Data loader + his test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd57a0c-8caf-45ec-bbaa-2bb476639714",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset,batch_size=BATCH_SIZE,shuffle= False)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dcdd43-de59-4520-a4bd-b984fac5ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification du DataLoader\n",
    "for img, mask, path in  test_dataloader:\n",
    "    print(f'Image batch shape: {img.shape}')\n",
    "    print(f'Mask batch shape: {mask.shape}')\n",
    "    print(f'Image path: {path[0]}')  # Afficher un chemin d'image pour v√©rifier\n",
    "    break  # Juste pour v√©rifier une premi√®re it√©ration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab4436-b744-4b75-9fa6-48db58ed0f96",
   "metadata": {},
   "source": [
    "## Visualize data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afdac86-b822-4c0f-85bb-0b9eda61b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtenir un index al√©atoire pour chaque dataset\n",
    "train_idx = np.random.randint(len(train_dataset))\n",
    "val_idx = np.random.randint(len(val_dataset))\n",
    "test_idx = np.random.randint(len(test_dataset))\n",
    "\n",
    "print(\"train_idx:\", train_idx)\n",
    "print(\"val_idx:\", val_idx)\n",
    "print(\"test_idx:\", test_idx)\n",
    "\n",
    "def plot_slice(dataset, index, dataset_name):\n",
    "    batch_data = dataset[index]\n",
    "    image, label = batch_data[0].to(device), batch_data[1].to(device)\n",
    "\n",
    "    # Conversion en numpy\n",
    "    image = image.squeeze().detach().cpu().numpy()\n",
    "    label = label.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    image = (image + 1) / 2.0  # Normaliser [0,1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    axes[0].imshow(image, cmap='gray')\n",
    "    axes[0].set_title(f\"{dataset_name} - Image\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(image, cmap='gray')\n",
    "    axes[1].imshow(label, cmap='Reds', alpha=0.4)\n",
    "    axes[1].set_title(f\"{dataset_name} - Overlay\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# üî• Afficher s√©par√©ment\n",
    "plot_slice(train_dataset, train_idx, dataset_name=\"Training\")\n",
    "plot_slice(val_dataset, val_idx, dataset_name=\"Validation\")\n",
    "plot_slice(test_dataset, test_idx, dataset_name=\"Test\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa8ad4d-41ec-49c0-b6e1-13b32dcdf875",
   "metadata": {},
   "source": [
    "## UNet Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a58548d-6f1d-4a21-b952-f7b1a0b80a8e",
   "metadata": {},
   "source": [
    "#### UNet params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a9d10-17e0-4fb3-8aae-efcab0156f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture Parameters\n",
    "input_channels = 1\n",
    "num_classes  = 1      #  e.g. 1 for binary segmentation (background vs object)\n",
    "input_shape = (input_channels, width, height)  # This is the shape of the input image to the network\n",
    "output_shape = (num_classes, width, height)  # This is the shape of the output mask\n",
    "init_channels = 32              # This is the number of channels in the first layer of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d79ca-c2fb-4c51-b109-c41fda34e701",
   "metadata": {},
   "source": [
    "#### The UNet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a58846-a6d0-4916-afd1-e555787c671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet\n",
    "\n",
    "# Define a Unet with  monai, lighter than Class Unet \n",
    "# Creation of the model U-Net with MONAI\n",
    "model = UNet(\n",
    "    spatial_dims = 2,                   # 2D U-Net\n",
    "    in_channels = 1,                    # e.g. 3 for RGB, 1 for grayscale input images\n",
    "    out_channels = 1,                   # 1 for binary segmentation\n",
    "    channels = (16, 32, 64, 128, 256),  # Nombres de canaux aux diff√©rents niveaux d'encodage\n",
    "    strides = (2, 2, 2, 2),             # Strides de downsampling (mod√®le aura 4 niveaux) \n",
    "    num_res_units=1                     # Nombre d'unit√©s r√©siduelles par bloc\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535339d9-081b-40f3-bd7e-401657ed6f41",
   "metadata": {},
   "source": [
    "#### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc94c5d-ebdf-440f-8973-0619832de6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_epochs = 50 # ou 100 car les l√©sions sont petites\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "\n",
    "# Option 1 : Utiliser Dice Loss seule\n",
    "criterion = DiceLoss(sigmoid=True)\n",
    "\n",
    "# Option 2 (recommand√©e) : Combiner Dice + BCE\n",
    "class ComboLoss(nn.Module):\n",
    "    def __init__(self, dice_weight=0.7):\n",
    "        super().__init__()\n",
    "        self.dice = DiceLoss(sigmoid=True)\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([20.0]).to(device))  # 20 peut √™tre ajust√©\n",
    "        self.dice_weight = dice_weight\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        dice_loss = self.dice(inputs, targets)\n",
    "        bce_loss = self.bce(inputs, targets)\n",
    "        return self.dice_weight * dice_loss + (1 - self.dice_weight) * bce_loss\n",
    "\n",
    "criterion = ComboLoss(dice_weight=0.7)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d93099-e92c-4911-912e-a7a577715e48",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09194d74-1a77-475b-9d14-78d3d6ebf581",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# D√©placement du mod√®le sur le device\n",
    "model = model.to(device)\n",
    "\n",
    "# Listes pour stocker les pertes\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "best_metric = -1\n",
    "best_valid_loss = float('inf')\n",
    "best_model = None\n",
    "best_epoch = 0\n",
    "\n",
    "model.train()  # mettre en mode entra√Ænement\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    ###################\n",
    "    # Phase entra√Ænement\n",
    "    ###################\n",
    "    for batch_data in tqdm(train_dataloader, position=0, leave=True):\n",
    "        images, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(images)\n",
    "\n",
    "        loss = criterion(output, labels)  # ici output brut pour la loss (pas de sigmoid ici)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_dataloader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    ###################\n",
    "    # Phase validation\n",
    "    ###################\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(val_dataloader, position=0, leave=True):\n",
    "            val_inputs, val_labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss = criterion(val_outputs, val_labels)  # pareil : output brut\n",
    "\n",
    "            valid_loss += val_loss.item() * val_inputs.size(0)\n",
    "\n",
    "        valid_loss = valid_loss / len(val_dataloader.dataset)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        print(f'Epoch: {epoch+1} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}')\n",
    "\n",
    "        # Sauvegarde du meilleur mod√®le\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_model = model.state_dict()\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "print(f\"‚úÖ Best model selected at epoch {best_epoch} with validation loss: {best_valid_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e60547-0f9b-4475-98b5-e0ef94a7b79a",
   "metadata": {},
   "source": [
    "#### We save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff85cdb-807f-49e9-a9a8-c9f64428ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_model)\n",
    "torch.save(best_model, 'best_model_3.pth')  # Save the best model\n",
    "print(f\"Best model selected at epoch {best_epoch} with validation loss: {best_valid_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a58136-aeef-4d5e-b1a5-016775996644",
   "metadata": {},
   "source": [
    "## Display Train Curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83594947-629b-4a74-8b22-155ea65e9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Plotting Training and Validation Loss\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e167c0-a893-4712-98fa-b81130bb424a",
   "metadata": {},
   "source": [
    "## Load and test the \"best\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e4164-c00e-4d1b-a387-9908d133f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load and use the best model\n",
    "\n",
    "input_shape = (1, width, height)  # This is the shape of the input image to the network\n",
    "num_classes = 1  # This is the number of output classes\n",
    "output_shape = (num_classes, width, height)  # This is the shape of the output mask\n",
    "init_channels = 32  # This is the number of channels in the first layer of the network\n",
    "\n",
    "#model = UNet(input_shape=input_shape, output_shape=output_shape, init_channels=init_channels).to(device)\n",
    "\n",
    "model_weights_path = \"best_model_2.pth\"\n",
    "model.load_state_dict(torch.load(model_weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f331d-60dc-48c6-b147-f1721724dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = os.cpu_count() - 1\n",
    "print(\"num_worker s=\",num_workers)\n",
    "\n",
    "# Create test_dataloader2, batch_size=1, just for the display of the following cell\n",
    "test_dataloader2 = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=1, \n",
    "    pin_memory=torch.cuda.is_available(), \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Create an iterator to iterate over the test dataloader\n",
    "test_dataloader_iter = iter(test_dataloader2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fdf39d-6fa4-4487-bf40-409d5b1f4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from monai.networks.nets import UNet\n",
    "from sklearn.metrics import jaccard_score\n",
    "from monai.metrics import DiceMetric, MeanIoU\n",
    "\n",
    "# --- METRICS MONAI ---\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "iou_metric = MeanIoU(include_background=False)\n",
    "\n",
    "# --- METRICS numpy ---\n",
    "def dice_score(pred, label):\n",
    "    pred = pred.astype(np.bool_)\n",
    "    label = label.astype(np.bool_)\n",
    "    intersection = np.logical_and(pred, label).sum()\n",
    "    return 2. * intersection / (pred.sum() + label.sum() + 1e-8)\n",
    "\n",
    "def iou_score(pred, label):\n",
    "    pred = pred.astype(np.bool_)\n",
    "    label = label.astype(np.bool_)\n",
    "    intersection = np.logical_and(pred, label).sum()\n",
    "    union = np.logical_or(pred, label).sum()\n",
    "    return intersection / (union + 1e-8)\n",
    "\n",
    "# --- FONCTION D'√âVALUATION ---\n",
    "def evaluate_model_on_batch(model, dataloader, device):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dice_metric.reset()\n",
    "    iou_metric.reset()\n",
    "\n",
    "    batch_data = next(iter(dataloader))  # prend un batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        images, labels, names = batch_data  # attention ici : dataset retourne aussi les noms !\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # prendre seulement la premi√®re image du batch\n",
    "        image = images[0].unsqueeze(0)  # [1, 1, H, W]\n",
    "        label = labels[0].unsqueeze(0)  # [1, 1, H, W]\n",
    "\n",
    "        print(\"Image shape:\", image.shape)\n",
    "\n",
    "        preds = model(image)\n",
    "\n",
    "        # Appliquer sigmoid + threshold\n",
    "        preds = torch.sigmoid(preds)\n",
    "        preds = (preds > 0.5).float()\n",
    "\n",
    "        # Calcul MONAI metrics\n",
    "        dice_metric(preds, label)\n",
    "        iou_metric(preds, label)\n",
    "        dice_metric_result = dice_metric.aggregate().item()\n",
    "        iou_metric_result = iou_metric.aggregate().item()\n",
    "\n",
    "        # --- Conversion numpy pour affichage ---\n",
    "        image_np = image.squeeze().detach().cpu().numpy()\n",
    "        label_np = label.squeeze().detach().cpu().numpy()\n",
    "        preds_np = preds.squeeze().detach().cpu().numpy()\n",
    "\n",
    "        # Normaliser l'image [-1,1] ‚Üí [0,1]\n",
    "        image_np = (image_np + 1) / 2.0\n",
    "\n",
    "        # Calcul numpy metrics\n",
    "        dice = dice_score(preds_np, label_np)\n",
    "        iou = iou_score(preds_np, label_np)\n",
    "\n",
    "    # --- AFFICHAGE ---\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "    axes[0, 0].imshow(image_np, cmap=\"gray\")\n",
    "    axes[0, 0].set_title(\"Image d'origine\")\n",
    "    axes[0, 0].axis(\"off\")\n",
    "\n",
    "    axes[0, 1].imshow(label_np, cmap=\"jet\")\n",
    "    axes[0, 1].set_title(\"Mask r√©el\")\n",
    "    axes[0, 1].axis(\"off\")\n",
    "\n",
    "    axes[0, 2].imshow(preds_np, cmap=\"jet\")\n",
    "    axes[0, 2].set_title(f\"Pr√©diction\\nDice: {dice:.3f} | IoU: {iou:.3f}\")\n",
    "    axes[0, 2].axis(\"off\")\n",
    "\n",
    "    axes[1, 0].imshow(image_np, cmap=\"gray\")\n",
    "    axes[1, 0].set_title(\"Image d'origine\")\n",
    "    axes[1, 0].axis(\"off\")\n",
    "\n",
    "    axes[1, 1].imshow(image_np, cmap=\"gray\")\n",
    "    axes[1, 1].imshow(label_np, cmap=\"Reds\", alpha=0.4)\n",
    "    axes[1, 1].set_title(\"Overlay Ground Truth\")\n",
    "    axes[1, 1].axis(\"off\")\n",
    "\n",
    "    axes[1, 2].imshow(image_np, cmap=\"gray\")\n",
    "    axes[1, 2].imshow(preds_np, cmap=\"Blues\", alpha=0.4)\n",
    "    axes[1, 2].set_title(\"Overlay Pr√©diction\")\n",
    "    axes[1, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"‚úÖ Dice (MONAI) : {dice_metric_result:.3f}\")\n",
    "    print(f\"‚úÖ IoU  (MONAI) : {iou_metric_result:.3f}\")\n",
    "    print(f\"‚úÖ Dice (NumPy) : {dice:.3f}\")\n",
    "    print(f\"‚úÖ IoU  (NumPy) : {iou:.3f}\")\n",
    "\n",
    "# --- UTILISATION ---\n",
    "# Exemple :\n",
    "# model = UNet(...)  # Ton mod√®le d√©j√† charg√©\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=1)\n",
    "\n",
    "evaluate_model_on_batch(model, test_dataloader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419e631-fc4f-4100-a477-fa07b3f9e1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
